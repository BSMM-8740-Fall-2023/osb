---
title: "Introduction to the Todyverse"
subtitle: "BSMM-8740 - Fall 2023"
author: "Dr. L.L. Odette"
footer:  "[bsmm-8740-fall-2023.github.io/osb](https://bsmm-8740-fall-2023.github.io/osb/)"
logo: "images/logo.png"
format: 
  revealjs: 
    theme: slides.scss
    multiplex: true
    transition: fade
    slide-number: true
editor: visual
execute:
  freeze: auto
---

```{r setup}
#| include: false
library(countdown)
knitr::opts_chunk$set(
  fig.width = 6,
  fig.asp = 0.618,
  fig.align = "center",
  out.width = "90%"
)
```

# Welcome

## Announcements

-   If you're just joining the class, welcome! Go to the [course website](https://bsmm-8740-fall-2023.github.io/osb/) and review content you've missed, read the syllabus, and complete the *Getting to know you* survey.
-   Lab 1 is due Friday, at 5pm, on Gradescope.

## Outline

-   Introduction to Tidyverse syntax
-   Estimate the slope and intercept of the regression line using the least squares method
-   Interpret the slope and intercept of the regression line

## Principles

From Wickham et al. ("Welcome to the Tidyverse." *Journal of Open Source Software* 4 (43)):

> "At a high level, the tidyverse is a language for solving data science challenges with R code. Its primary goal is to facilitate a conversation between a human and a computer about data. Less abstractly, the tidyverse is a collection of R packages that share a high-level design philosophy and low-level grammar and data structures, so that learning one package makes it easier to learn the next."

```{r packages}
#| echo: false
#| message: false

# load packages
library(tidyverse)       # for data wrangling
library(tidymodels)      # for modeling
library(fivethirtyeight) # for the fandango dataset

# set default theme and larger font size for ggplot2
ggplot2::theme_set(ggplot2::theme_minimal(base_size = 16))

# set default figure parameters for knitr
knitr::opts_chunk$set(
  fig.width = 8,
  fig.asp = 0.618,
  fig.retina = 3,
  dpi = 300,
  out.width = "80%"
)
```

## Principles

1.  Design for humans
2.  Reuse existing data structures
3.  Design for the pipe and functional programming

## Example

```{r}
#| echo: true
#| message: false
# attach package magrittr
require(magrittr)

url <- 
  "https://data.cityofchicago.org/api/views/5neh-572f/rows.csv?accessType=DOWNLOAD&bom=true&format=true"

all_stations <- 
  # Step 1: Read in the data.
  readr::read_csv(url) %>% 
  # Step 2: filter columns and rename stationname
  dplyr::select(station = stationname, date, rides) %>% 
  # Step 3: Convert the character date field to a date encoding.
  # Also, put the data in units of 1K rides
  dplyr::mutate(date = lubridate::mdy(date), rides = rides / 1000) %>% 
  # Step 4: Summarize the multiple records using the maximum.
  dplyr::group_by(date, station) %>% 
  dplyr::summarize(rides = max(rides), .groups = "drop")
```

## Magrittr vs native pipe

::: {style="font-size: 80%"}
| Topic         | Magrittr *2.0.3*     | Base *4.3.0*                       |
|---------------|----------------------|------------------------------------|
| Operator      | `%>%` `%<>%` `%T>%`  | `|>` (since 4.1.0)                 |
| Function call | `1:3 %>% sum()`      | `1:3 %>% sum()`                    |
|               | `1:3 %>% sum`        | *Needs brackets / parentheses*     |
|               | `` 1:3 %>% `+`(4) `` | *Some functions are not supported* |
| Placeholder   | `.`                  | `_` (since 4.2.0)                  |
:::

~based on [stackoverflow](https://stackoverflow.com/questions/67633022/what-are-the-differences-between-rs-new-native-pipe-and-the-magrittr-pipe)~

## Use cases for the Magrittr pipe

```{r}
#| echo: true
#| message: false
#| results: false

# functional programming
airlines <- fivethirtyeight::airline_safety %>% 
  # filter rows
  dplyr::filter( stringr::str_detect(airline, 'Air') )

# assignment
airlines %<>% 
  # filter columns and assign result to airlines
  dplyr::select(avail_seat_km_per_week, incidents_85_99, fatalities_85_99)

# side effects
airlines %T>% 
  # report the dimensions
  (\(x) print(dim(x)) ) %>% 
  # summarize
  dplyr::summarize(avail_seat_km_per_week = sum(avail_seat_km_per_week))
```

## Functions in R

```{r}
#| echo: true
#| message: false
#| results: false
# named function
is_awesome <- function(x = 'Bob') {
  paste(x, 'is awesome!')
}

# anonymous function
(function (x) {paste(x, 'is awesome!')})('Keith')

# also anonymous function
(\(x) paste(x, 'is awesome!'))('Keith')

# a function from a formula in the tidyverse
c('Bob','Ted') %>% purrr::map_chr(~paste(.x, 'is awesome!'))
```

# Data Wrangling

## Example 1a: mutate

```{r}
#| echo: true
#| message: false
#| results: false
openintro::email %>%
  dplyr::select(-from, -sent_email) %>%
  dplyr::mutate(
    day_of_week = lubridate::wday(time)       # new variable: day of week
    , month = lubridate::month(time)          # new variable: month
  ) %>%
  dplyr::select(-time) %>%
  dplyr::mutate(
    cc     = cut(cc, breaks = c(0, 1))        # discretize cc
    , attach = cut(attach, breaks = c(0, 1))  # discretize attach
    , dollar = cut(dollar, breaks = c(0, 1))  # discretize dollar
  ) %>%
  dplyr::mutate(
    inherit = 
      cut(inherit, breaks = c(0, 1, 5, 10, 20))  # discretize inherit, by intervals
    , password = dplyr::ntile(password, 5)       # discretize password, by quintile
  )
```

## Example 1b: mutate across

```{r}
#| echo: true
#| message: false
#| results: false
iris %>%
  dplyr::mutate(across(c(Sepal.Length, Sepal.Width), round))

iris %>%
  dplyr::mutate(across(c(1, 2), round))

iris %>%
  dplyr::group_by(Species) %>%
  dplyr::summarise(
    across( starts_with("Sepal"), list(mean = mean, sd = sd) )
  )

iris %>%
  dplyr::group_by(Species) %>%
  dplyr::summarise(
    across( starts_with("Sepal"), ~ mean(.x, na.rm = TRUE) )
  )

```

## Example 2: rowwise operations

::: panel-tabset
## rowwise operations

The verb ***rowwise*** creates a special type of grouping where each group consists of a single row.

```{r}
#| echo: true
#| message: false
#| results: false
iris %>%
  dplyr::rowwise() %>%
  dplyr::mutate( 
    mean_length = 
      mean( c(Sepal.Length, Petal.Length) )
    , .before = 1
  ) %>% 
  dplyr::ungroup()
```

## using c_across

```{r}
#| echo: true
#| message: false
#| results: false
iris %>%
  dplyr::rowwise() %>%
  dplyr::mutate( 
    mean_length = 
      mean(
        dplyr::c_across(c(Sepal.Length:Petal.Width))
      )
    , .before = 1 
  ) %>% 
  dplyr::ungroup()
```
:::

## Example 3: nesting operations

::: panel-tabset
## list columns

```{r}
#| echo: true
#| message: false
#| code-fold: true
#| code-summary: "create a list-column of data frames"
(df1 <- tibble::tibble(
  g = c(1, 2, 3),
  data = list(
    tibble::tibble(x = 1, y = 2),
    tibble::tibble(x = 4:5, y = 6:7),
    tibble::tibble(x = 10)
  )
) )
```

## group-nesting

```{r}
#| echo: true
#| message: false
#| code-fold: true
#| code-summary: "nest groups by continent, country"
(gapminder_nest <- gapminder::gapminder %>% 
  dplyr::mutate(year1950 = year - 1950) %>% 
  dplyr::group_nest(continent, country)
)
```

## mapping

```{r}
#| echo: true
#| message: false
#| code-fold: true
#| code-summary: "Fit a linear model for each country:"
(gapminder_model <- gapminder_nest %>% 
  dplyr::mutate(
    model = 
      purrr::map(
        data
        , ~lm(lifeExp ~ year1950, data = .))
  ))
```
:::

## Example 4: stringr string functions

Main verbs, each taking a pattern as input

::: panel-tabset
## stringr::str\_{X}

```{r}
#| echo: true
#| message: false
#| results: false
x <- c("why", "video", "cross", "extra", "deal", "authority")

stringr::str_detect(x, "[aeiou]")       # identifies any matches
stringr::str_count(x, "[aeiou]")        # counts number of patterns
stringr::str_subset(x, "[aeiou]")       # extracts matching components
stringr::str_extract(x, "[aeiou]")      # extracts text of the match
stringr::str_replace(x, "[aeiou]", "?") # replaces matches with new text:
stringr::str_split(x, ",")              # splits up a string

```

## stringr::str_glue

```{r}
#| echo: true
#| message: false
#| results: false

mtcars %>% 
  tibble::rownames_to_column(var = "car") %>% 
  tibble::as_tibble() %T>% 
  (\(x) print(names(x)) ) %>% 
  dplyr::mutate(
    note = stringr::str_glue("The {car} has {cyl} cylinders")) %>% 
  dplyr::slice_head(n=3)
```
:::

[cheat sheet](https://github.com/rstudio/cheatsheets/blob/main/strings.pdf)

# Data

## Movie ratings

::: columns
::: {.column width="70%"}
-   Data behind the FiveThirtyEight story [*Be Suspicious Of Online Movie Ratings, Especially Fandango's*](%22Be%20Suspicious%20Of%20Online%20Movie%20Ratings,%20Especially%20Fandango's%22)
-   In the **fivethirtyeight** package: [`fandango`](https://fivethirtyeight-r.netlify.app/reference/fandango.html)
-   Contains every film that has at least 30 fan reviews on Fandango, an IMDb score, Rotten Tomatoes critic and user ratings, and Metacritic critic and user scores
:::

::: {.column width="30%"}
![](images/lec-2/fandango.png){fig-alt="Fandango logo" width="200"}

![](images/lec-2/imdb.png){fig-alt="IMDB logo" width="200"}

![](images/lec-2/rotten-tomatoes.png){fig-alt="Rotten Tomatoes logo" width="200"}

![](images/lec-2/metacritic.png){fig-alt="Metacritic logo" width="200"}
:::
:::

## Data prep

-   Rename Rotten Tomatoes columns as `critics` and `audience`
-   Rename the dataset as `movie_scores`

```{r data-prep}
#| echo: true
movie_scores <- fandango %>%
  rename(
    critics = rottentomatoes, 
    audience = rottentomatoes_user
  )
```

## Data overview

```{r data-overview}
#| echo: true
glimpse(movie_scores)
```

## Data visualization

```{r}
ggplot(movie_scores, 
       aes(x = critics, y = audience)) +
  geom_point(alpha = 0.5) + 
  labs(
    x = "Critics Score" , 
    y = "Audience Score"
    )
```

# Regression model

## Fit a line

... to *describe* the relationship between the critics and audience score

```{r}
#| out.width: "70%"
p <- ggplot(data = movie_scores, 
       mapping = aes(x = critics, y = audience)) +
  geom_point(alpha = 0.5) + 
  geom_smooth(method = "lm", color = "purple", se = FALSE) +
  labs(
    x = "Critics Score" , 
    y = "Audience Score"
    )

p
```

## Terminology

::: columns
::: {.column width="30%"}
-   **Outcome, *Y***: variable describing the outcome of interest
-   **Predictor, X**: variable used to help understand the variability in the outcome
:::

::: {.column width="70%"}
```{r}
#| out.width: "100%"
p
```
:::
:::

## Regression model {#regression-model-1}

A **regression model** is a function that describes the relationship between the outcome, $Y$, and the predictor, $X$.

$$\begin{aligned} Y &= \color{black}{\textbf{Model}} + \text{Error} \\[8pt]
&= \color{black}{\mathbf{f(X)}} + \epsilon \\[8pt]
&= \color{black}{\boldsymbol{\mu_{Y|X}}} + \epsilon \end{aligned}$$

## Regression model

::: columns
::: {.column width="30%"}
$$
\begin{aligned} Y &= \color{purple}{\textbf{Model}} + \text{Error} \\[8pt]
&= \color{purple}{\mathbf{f(X)}} + \epsilon \\[8pt]
&= \color{purple}{\boldsymbol{\mu_{Y|X}}} + \epsilon 
\end{aligned}
$$
:::

::: {.column width="70%"}
```{r}
m <- lm(audience ~ critics, data = movie_scores)

ggplot(data = movie_scores, 
       mapping = aes(x = critics, y = audience)) +
  geom_point(alpha = 0.5) + 
  geom_smooth(method = "lm", color = "purple", se = FALSE) +
  labs(x = "X", y = "Y") +
  theme_minimal() +
  theme(
    axis.text = element_blank(),
    axis.ticks.x = element_blank(), 
    axis.ticks.y = element_blank()
    )
```
:::
:::

## Regression model + residuals

::: columns
::: {.column width="30%"}
$$\begin{aligned} Y &= \color{purple}{\textbf{Model}} + \color{blue}{\textbf{Error}} \\[8pt]
&= \color{purple}{\mathbf{f(X)}} + \color{blue}{\boldsymbol{\epsilon}} \\[8pt]
&= \color{purple}{\boldsymbol{\mu_{Y|X}}} + \color{blue}{\boldsymbol{\epsilon}} \\[8pt]
 \end{aligned}$$
:::

::: {.column width="70%"}
```{r}
#| echo: false
ggplot(data = movie_scores,
       mapping = aes(x = critics, y = audience)) +
  geom_point(alpha = 0.5) +
  geom_smooth(method = "lm", color = "purple", se = FALSE) +
  geom_segment(aes(x = critics, xend = critics, 
                   y = audience, yend = predict(m)), 
               color = "blue") +
  labs(x = "X", y = "Y") +
  theme(
    axis.text = element_blank(),
    axis.ticks.x = element_blank(),
    axis.ticks.y = element_blank()
  )
```
:::
:::

# Simple linear regression

## Simple linear regression

Use **simple linear regression** to model the relationthip between a quantitative outcome ($Y$) and a single quantitative predictor ($X$): $$\Large{Y = \beta_0 + \beta_1 X + \epsilon}$$

::: incremental
-   $\beta_1$: True slope of the relationship between $X$ and $Y$
-   $\beta_0$: True intercept of the relationship between $X$ and $Y$
-   $\epsilon$: Error (residual)
:::

## Simple linear regression

$$\Large{\hat{Y} = \hat{\beta}_0 + \hat{\beta}_1 X}$$

-   $\hat{\beta}_1$: Estimated slope of the relationship between $X$ and $Y$
-   $\hat{\beta}_0$: Estimated intercept of the relationship between $X$ and $Y$
-   No error term!

## Choosing values for $\hat{\beta}_1$ and $\hat{\beta}_0$

```{r}
ggplot(data = movie_scores, 
       mapping = aes(x = critics, y = audience)) +
  geom_point(alpha = 0.4) + 
  geom_abline(intercept = 32.3155, slope = 0.5187, color = "purple", size = 1) +
  geom_abline(intercept = 25, slope = 0.7, color = "gray") +
  geom_abline(intercept = 21, slope = 0.9, color = "gray") +
  geom_abline(intercept = 35, slope = 0.3, color = "gray") +
  labs(x = "Critics Score", y = "Audience Score")
```

## Residuals

```{r}
#| warning: false
#| message: false
ggplot(data = movie_scores, mapping = aes(x = critics, y = audience)) +
  geom_point(alpha = 0.5) +
  geom_smooth(method = "lm", color = "purple", se = FALSE) +
  geom_segment(aes(x = critics, xend = critics, y = audience, yend = predict(m)), color = "steel blue") +
  labs(x = "Critics Score", y = "Audience Score") +
  theme(legend.position = "none")
```

$$\text{residual} = \text{observed} - \text{predicted} = y - \hat{y}$$

## Least squares line

-   The residual for the $i^{th}$ observation is

$$e_i = \text{observed} - \text{predicted} = y_i - \hat{y}_i$$

-   The **sum of squared** residuals is

$$e^2_1 + e^2_2 + \dots + e^2_n$$

-   The **least squares line** is the one that minimizes the sum of squared residuals

```{r}
sx <- round(sqrt(var(movie_scores$critics)), 4)
sy <- round(sqrt(var(movie_scores$audience)), 4)
r <- round(cor(movie_scores$critics, movie_scores$audience), 4)
xbar <- round(mean(movie_scores$critics), 4)
ybar <- round(mean(movie_scores$audience), 4)
```

# Slope and intercept

## Properties of least squares regression

-   The regression line goes through the center of mass point, the coordinates corresponding to average $X$ and average $Y$: $\hat{\beta}_0 = \bar{Y} - \hat{\beta}_1\bar{X}$

-   The slope has the same sign as the correlation coefficient: $\hat{\beta}_1 = r \frac{s_Y}{s_X}$

-   The sum of the residuals is zero: $\sum_{i = 1}^n \epsilon_i = 0$

-   The residuals and $X$ values are uncorrelated

## Estimating the slope

$$\large{\hat{\beta}_1 = r \frac{s_Y}{s_X}}$$

::: columns
::: {.column width="50%"}
$$
\begin{aligned} 
s_X &= 30.1688 \\
s_Y &=  20.0244 \\
r &= 0.7814
\end{aligned}
$$
:::

::: {.column width="50%"}
$$
\begin{aligned}
\hat{\beta}_1 &= 0.7814 \times \frac{20.0244}{30.1688} \\
&= 0.5187\end{aligned}
$$
:::
:::

## Estimating the intercept

$$\large{\hat{\beta}_0 = \bar{Y} - \hat{\beta}_1\bar{X}}$$

::: columns
::: {.column width="50%"}
$$\begin{aligned}
&\bar{x} = 60.8493 \\
&\bar{y} = 63.8767 \\
&\hat{\beta}_1 = 0.5187
\end{aligned}$$
:::

::: {.column width="50%"}
$$
\begin{aligned}\hat{\beta}_0 &= 63.8767 - 0.5187 \times 60.8493 \\
&= 32.3142
\end{aligned}
$$
:::
:::

## Interpreting the slope {.smaller}

**Poll:** The slope of the model for predicting audience score from critics score is 32.3142. Which of the following is the best interpretation of this value?

-   For every one point increase in the critics score, the audience score goes up by 0.5187 points, on average.
-   For every one point increase in the critics score, we expect the audience score to be higher by 0.5187 points, on average.
-   For every one point increase in the critics score, the audience score goes up by 0.5187 points.
-   For every one point increase in the audience score, the critics score goes up by 0.5187 points, on average.

## Interpreting slope & intercept

$$\widehat{\text{audience}} = 32.3142 + 0.5187 \times \text{critics}$$

::: incremental
-   **Slope:** For every one point increase in the critics score, we expect the audience score to be higher by 0.5187 points, on average.
-   **Intercept:** If the critics score is 0 points, we expect the audience score to be 32.3142 points.
:::

## Is the intercept meaningful?

✅ The intercept is meaningful in context of the data if

-   the predictor can feasibly take values equal to or near zero or
-   the predictor has values near zero in the observed data

. . .

🛑 Otherwise, it might not be meaningful!

# Prediction

## Making a prediction

Suppose that a movie has a critics score of 50. According to this model, what is the movie's predicted audience score?

$$
\begin{aligned}
\widehat{\text{audience}} &= 32.3142 + 0.5187 \times \text{critics} \\
&= 32.3142 + 0.5187 \times 50 \\
&= 58.2492
\end{aligned}
$$

## Extrapolation

Suppose that a movie has a critics score of 0. According to this model, what is the movie's predicted audience score?

```{r}
p + coord_cartesian(xlim = c(0, 100))
```

# Recap

## Recap {.smaller}

::: incremental
-   Used simple linear regression to describe the relationship between a quantitative predictor and quantitative outcome variable.

-   Used the least squares method to estimate the slope and intercept.å

-   We interpreted the slope and intercept.

    ::: incremental
    -   **Slope:** For every one unit increase in $x$, we expect y to be higher/lower by $\hat{\beta}_1$ units, on average.
    -   **Intercept:** If $x$ is 0, then we expect $y$ to be $\hat{\beta}_0$ units.
    :::

-   Predicted the response given a value of the predictor variable.

-   Defined extrapolation and why we should avoid it.
:::
